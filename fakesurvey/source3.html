<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Barbara Felderer">
<meta name="dcterms.date" content="2024-01-01">

<title>Nonresponse Bias Analysis – GESIS Guides</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./logos/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7e6f1cd7014c343ccf2b75fa0c32076c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./logos/logo_gesis_en.png" alt="GESIS logo." class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./source.html"> 
<span class="menu-text">from pdf</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./source2.html"> 
<span class="menu-text">from MS Word</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./source3.html" aria-current="page"> 
<span class="menu-text">from rmd</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">1. Introduction</a></li>
  <li><a href="#relationship-of-survey-nonresponse-and-nonresponse-bias" id="toc-relationship-of-survey-nonresponse-and-nonresponse-bias" class="nav-link" data-scroll-target="#relationship-of-survey-nonresponse-and-nonresponse-bias">2. Relationship of survey nonresponse and nonresponse bias</a>
  <ul class="collapse">
  <li><a href="#threemodels" id="toc-threemodels" class="nav-link" data-scroll-target="#threemodels">2.1 Nonresponse mechanisms</a></li>
  <li><a href="#different-perspectives-on-nonresponse-bias" id="toc-different-perspectives-on-nonresponse-bias" class="nav-link" data-scroll-target="#different-perspectives-on-nonresponse-bias">2.2 Different perspectives on nonresponse bias</a></li>
  <li><a href="#why-is-the-response-rate-alone-not-a-reliable-indicator-of-nonresponse-bias" id="toc-why-is-the-response-rate-alone-not-a-reliable-indicator-of-nonresponse-bias" class="nav-link" data-scroll-target="#why-is-the-response-rate-alone-not-a-reliable-indicator-of-nonresponse-bias">2.3 Why is the response rate alone not a reliable indicator of nonresponse bias?</a></li>
  </ul></li>
  <li><a href="#nonresponse-bias-analysis" id="toc-nonresponse-bias-analysis" class="nav-link" data-scroll-target="#nonresponse-bias-analysis">3. Nonresponse bias analysis</a>
  <ul class="collapse">
  <li><a href="#components-of-nonresponse-bias-analysis" id="toc-components-of-nonresponse-bias-analysis" class="nav-link" data-scroll-target="#components-of-nonresponse-bias-analysis">3.1 Components of nonresponse bias analysis</a></li>
  <li><a href="#multivariate-nonresponse-bias-indicators" id="toc-multivariate-nonresponse-bias-indicators" class="nav-link" data-scroll-target="#multivariate-nonresponse-bias-indicators">3.2 Multivariate nonresponse bias indicators</a>
  <ul class="collapse">
  <li><a href="#r-indicator" id="toc-r-indicator" class="nav-link" data-scroll-target="#r-indicator">R-indicator</a></li>
  <li><a href="#goodness-of-fit-of-the-propensity-model" id="toc-goodness-of-fit-of-the-propensity-model" class="nav-link" data-scroll-target="#goodness-of-fit-of-the-propensity-model">Goodness of fit of the propensity model</a></li>
  <li><a href="#variation-of-nonresponse-weights" id="toc-variation-of-nonresponse-weights" class="nav-link" data-scroll-target="#variation-of-nonresponse-weights">Variation of nonresponse weights</a></li>
  <li><a href="#correlation-between-nonresponse-weights-and-y" id="toc-correlation-between-nonresponse-weights-and-y" class="nav-link" data-scroll-target="#correlation-between-nonresponse-weights-and-y">Correlation between nonresponse weights and <span class="math inline">\(Y\)</span></a></li>
  <li><a href="#fraction-of-missing-information" id="toc-fraction-of-missing-information" class="nav-link" data-scroll-target="#fraction-of-missing-information">Fraction of missing information</a></li>
  </ul></li>
  <li><a href="#univariate-nonresponse-bias-indicators" id="toc-univariate-nonresponse-bias-indicators" class="nav-link" data-scroll-target="#univariate-nonresponse-bias-indicators">3.3 Univariate nonresponse bias indicators</a>
  <ul class="collapse">
  <li><a href="#benchmark-comparisons" id="toc-benchmark-comparisons" class="nav-link" data-scroll-target="#benchmark-comparisons">Benchmark comparisons</a></li>
  <li><a href="#comparison-of-respondents-and-nonrespondents-on-auxiliary-variables" id="toc-comparison-of-respondents-and-nonrespondents-on-auxiliary-variables" class="nav-link" data-scroll-target="#comparison-of-respondents-and-nonrespondents-on-auxiliary-variables">Comparison of respondents and nonrespondents on auxiliary variables</a></li>
  <li><a href="#comparison-of-early-and-late-respondents" id="toc-comparison-of-early-and-late-respondents" class="nav-link" data-scroll-target="#comparison-of-early-and-late-respondents">Comparison of early and late respondents</a></li>
  <li><a href="#variation-of-subgroup-response-rates" id="toc-variation-of-subgroup-response-rates" class="nav-link" data-scroll-target="#variation-of-subgroup-response-rates">Variation of subgroup response rates</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#illustration-of-use-of-nonresponse-bias-indicators" id="toc-illustration-of-use-of-nonresponse-bias-indicators" class="nav-link" data-scroll-target="#illustration-of-use-of-nonresponse-bias-indicators">4. Illustration of use of nonresponse bias indicators</a>
  <ul class="collapse">
  <li><a href="#multivariate-nonresponse-bias-indicators-1" id="toc-multivariate-nonresponse-bias-indicators-1" class="nav-link" data-scroll-target="#multivariate-nonresponse-bias-indicators-1">4.1 Multivariate nonresponse bias indicators</a></li>
  <li><a href="#univariate-nonresponse-bias-indicators-1" id="toc-univariate-nonresponse-bias-indicators-1" class="nav-link" data-scroll-target="#univariate-nonresponse-bias-indicators-1">4.2 Univariate nonresponse bias indicators</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">5. Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="source3.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Nonresponse Bias Analysis</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Barbara Felderer </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2024</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>Declining response rates increase the fear of nonresponse bias. This guideline discusses the relationship between nonresponse and nonrespones bias and gives an overview of indicators that are frequently used to determine the risk of nonresponse bias. The indicators are illustrated in a simulated data example.</p>
  </div>
</div>


</header>


<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>Declining response rates all over the world increase the fear of nonresponse bias, i.e., that the respondents to a survey do not well represent the group of individuals who has been invited to participate in that survey. In the presence of nonresponse bias, raw survey estimates can not be used to draw valid conclusions on the population of interest.</p>
<p>High nonresponse does not necessarily imply high nonresponse bias. This guideline discusses the relationship between nonresponse and nonresponse bias and gives an overview of methods to determine nonresponse bias for a specific survey or survey variable of interest. Talking about survey nonresponse, we can in general distinguish between item nonresponse and unit nonresponse. Unit nonresponse means that an individual who is sampled and invited to participate in a survey does not participate in that survey at all. Item nonresponse occurs if an interviewed person does not give an answer to a specific question. This guideline captures unit nonresponse, for a discussion of the handling of item nonresponse we refer to the GESIS survey guideline on imputation <span class="citation" data-cites="Bruch2023">(<a href="#ref-Bruch2023" role="doc-biblioref">Bruch, 2023</a>)</span>. Adjustment methods might be applied to reduce nonresponse bias but they only work under certain conditions that are discussed in this guideline. This guideline does, however, not address the treatment nor the prevention of nonresponse bias. For the former, we recommend the survey guidelines on weighting <span class="citation" data-cites="Gabler2015 Sand2020">(<a href="#ref-Gabler2015" role="doc-biblioref">Gabler et al., 2015</a>; <a href="#ref-Sand2020" role="doc-biblioref">Sand &amp; Kunz, 2020</a>)</span>, for the latter the survey guideline on nonresponse bias <span class="citation" data-cites="Koch2015">(<a href="#ref-Koch2015" role="doc-biblioref">Koch &amp; Blohm, 2015</a>)</span>.</p>
<p>Nonresponse is by far not the only source of potential survey error <span class="citation" data-cites="groves2010total">(<a href="#ref-groves2010total" role="doc-biblioref">Groves &amp; Lyberg, 2010</a>)</span>. For simplicity, this guideline ignores all other sources of error, for example, we assume simple random sampling and measurements without error or item nonresponse. The next section discusses the relationship between survey nonresponse and nonresponse bias. Several univariate and multivariate indicators for the risk of nonresponse bias are discussed in Section 3. In Section 4, we illustrate some of the nonresponse bias indicators using a synthetic data example. A R-file to replicate the example is made available online. We conclude with a discussion in Section 5.</p>
</section>
<section id="relationship-of-survey-nonresponse-and-nonresponse-bias" class="level1">
<h1>2. Relationship of survey nonresponse and nonresponse bias</h1>
<p>In the following, we denote the survey variables by <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, <span class="math inline">\(Z\)</span>, and the matrix and vector of their observed values by <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(z\)</span>. Unit nonresponse can occur for several reasons and is not necessarily a problem for the quality of the survey. Let <span class="math inline">\(Y\)</span> be the survey variable of interest that one plans to analyse, <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> be two distinct sets of personal characteristics of the invited individual and <span class="math inline">\(\rho \in [0,1]\)</span> be response propensities.</p>
<section id="threemodels" class="level2">
<h2 data-anchor-id="threemodels">2.1 Nonresponse mechanisms</h2>
<p><span class="citation" data-cites="groves2006nonresponse">Groves (<a href="#ref-groves2006nonresponse" role="doc-biblioref">2006</a>)</span> distinguishes between three nonresponse mechanisms that can be explained by different models:</p>
<p><strong>Separate Cause Model</strong>: The response propensity <span class="math inline">\(\rho\)</span> depends on personal characteristics <span class="math inline">\(Z\)</span> that are not associated with the variable of interest <span class="math inline">\(Y\)</span>. <span class="math inline">\(Y\)</span> is associated with personal characteristics <span class="math inline">\(X\)</span> that do not affect the response propensity <span class="math inline">\(\rho\)</span>. In this situation, <span class="math inline">\(Y\)</span> and <span class="math inline">\(\rho\)</span> are not associated. This means that nonresponse does not lead to nonresponse bias in the analysis of <span class="math inline">\(Y\)</span>.</p>
<p>As <span class="citation" data-cites="groves2006nonresponse">Groves (<a href="#ref-groves2006nonresponse" role="doc-biblioref">2006</a>)</span> notes, completely unrelated causes are hard to imagine in practice. The separate cause model is, however, very useful when thinking of the relationship of nonresponse and nonresponse bias and to contrast the other models against it.</p>
<p><strong>Common Cause Model</strong>: The same individual characteristics <span class="math inline">\(Z\)</span> affect the response propensity <span class="math inline">\(\rho\)</span> and the variable of interest <span class="math inline">\(Y\)</span>. The common cause generates an association between <span class="math inline">\(\rho\)</span> and <span class="math inline">\(Y\)</span> thus potentially biasing the analysis of <span class="math inline">\(Y\)</span>.</p>
<p>If <span class="math inline">\(Z\)</span> is known for respondents and nonresponents, it can be used to perform nonresponse adjustments in the analysis of the survey variable <span class="math inline">\(Y\)</span> and to reduce nonresponse bias. Like the separate cause model, the common cause model is a simplified model. In practical applications, there will most likely be unboserved <span class="math inline">\(Z\)</span>-variables that can not be included in the nonresponse adjustment.</p>
<p><strong>Survey Variable Cause Model</strong>: The variable of interest <span class="math inline">\(Y\)</span> directly affects the response propensity <span class="math inline">\(\rho\)</span>. Since <span class="math inline">\(\rho\)</span> and <span class="math inline">\(Y\)</span> are associated, analysis of <span class="math inline">\(Y\)</span> will suffer from nonresponse bias, and this can not be completely removed by any weighting or adjustment method.</p>
<p>It is important to note that different nonresponse models might hold for different variables <span class="math inline">\(Y\)</span> of the same survey. The nonresponse mechanism and thus nonresponse bias is always variable-specific.</p>
</section>
<section id="different-perspectives-on-nonresponse-bias" class="level2">
<h2 data-anchor-id="different-perspectives-on-nonresponse-bias">2.2 Different perspectives on nonresponse bias</h2>
<p>Nonresponse bias can be viewed from several perspectives that highlight different facets.</p>
<p>We differentiate between three groups: The overall target population (with size <span class="math inline">\(N^*\)</span>), the sampled individuals (with size <span class="math inline">\(N\)</span>), and the survey respondents (with size <span class="math inline">\(n\)</span>), where <span class="math inline">\(N^* &gt; N \geq n\)</span>. In this guideline, we assume that the survey sample is randomly drawn from the target population. For ease of exposition we further assume a simple random sample, i.e., sampling with equal inclusion probabilities.</p>
<p>With <span class="math inline">\(y_i\)</span> being the value for survey variable <span class="math inline">\(Y\)</span> for individual <span class="math inline">\(i\)</span>, the population mean of <span class="math inline">\(Y\)</span> is given by <span class="math inline">\(\bar{y}_P = 1/N^* \sum_{i=1}^{N^*} y_i\)</span>, the mean of the sampled individuals by <span class="math inline">\(\bar{y}_S = 1/N \sum_{i=1}^{N} y_i\)</span>, and the mean of the survey respondents by <span class="math inline">\(\bar{y}_R = 1/n \sum_{i=1}^{n} y_i\)</span>. For more complex survey designs with unequal inclusion probabilities, survey estimates must to be design-weighted.</p>
<p>Nonresponse bias (NRB) in the estimated mean of a survey variable <span class="math inline">\(Y\)</span> is given by the difference between the mean value of the survey respondents <span class="math inline">\(\bar{y}_R\)</span> and the mean of the target population <span class="math inline">\(\bar{y}_P\)</span>. Assuming random sampling, <span class="math inline">\(\bar{y}_P = \bar{y}_S\)</span> holds, such that</p>
<p><span class="math display">\[
\begin{align}
NRB_Y = \bar{y}_R - \bar{y}_S.
\end{align}
\]</span></p>
<p>As can easily be seen, we do not have to expect nonresponse bias in <span class="math inline">\(\bar{y}_R\)</span> if respondents do not differ from the target population in <span class="math inline">\(Y\)</span> on average. Nonresponse bias gets larger as the difference increases.</p>
<p>Looking at this relationship more closely, usually the deterministic and the stochastic view on nonresponse bias are distinguished. Even though they refer to the exact same concept, they highlight different aspects making it worth to look at both of them.</p>
<p>The <em>deterministic</em> view on nonresponse bias is given by <span class="citation" data-cites="groves2006nonresponse">(see for example <a href="#ref-groves2006nonresponse" role="doc-biblioref">Groves, 2006</a>)</span>:</p>
<p><span class="math display">\[
\begin{align}
NRB_Y = (1-RR) (\bar{y}_R - \bar{y}_{NR}),
\end{align}
\]</span></p>
<p>where <span class="math inline">\(RR = \frac{n}{N}\)</span> is the response rate and the mean of the nonrespondents is given by <span class="math inline">\(\bar{y}_{NR}\)</span>. Nonresponse bias is affected by the response rate and the difference between means for respondents and nonrespondents. This means two things: For a given difference between respondents and nonrespondents, an increasing response rate will lower nonresponse bias. For a given response rate, lower differences between respondents and nonrespondents lead to lower nonresponse bias. If respondents and nonrespondents do not differ in <span class="math inline">\(Y\)</span> at all, no nonresponse bias is to be expected in <span class="math inline">\(Y\)</span>.</p>
<p>The <em>stochastic</em> approach takes the perspective that participants are not determined to be either respondents or nonrespondents, but characterized by a latent, stochastic propensity to respond. Taking this approach, nonresponse bias is computed over all elements of the target population, weighted by their unobserved response propensities <span class="math inline">\(\rho_i\)</span>. This gives rise to the following definition <span class="citation" data-cites="bethlehem1988reduction">(<a href="#ref-bethlehem1988reduction" role="doc-biblioref">Bethlehem, 1988</a>)</span>:</p>
<p><span class="math display">\[
\begin{align}
NRB_{Y} &amp;  \approx \frac{1}{\bar{\rho}} Cov(y, \rho)
\nonumber \\
&amp; \approx \frac{1}{\bar{\rho}} Cor (y, \rho) \sigma_y \sigma_\rho
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\rho\)</span> is the vector (of length <span class="math inline">\(N^*\)</span>) of response propensities with population mean <span class="math inline">\(\bar{\rho}\)</span>. The population covariance of <span class="math inline">\(y\)</span> and <span class="math inline">\(\rho\)</span> is given by <span class="math inline">\(Cov(y, \rho) = 1/N^* \sum_{i=1}^{N^*} (y_i - \bar{y}_P)(\rho_i - \bar{\rho})\)</span>. The population standard deviations of <span class="math inline">\(y\)</span> and <span class="math inline">\(\rho\)</span> are <span class="math inline">\(\sigma_y = \sqrt{{1}/{N^*} \sum_{i=1}^{N} (y_i - \bar{y})^2}\)</span> and <span class="math inline">\(\sigma_\rho = \sqrt{{1}/{N^*} \sum_{i=1}^{N} (\rho_i - \bar{\rho})^2}\)</span>, and <span class="math inline">\(Cor(y, \rho) = \frac{Cov (y, \rho)}{\sigma_y \sigma_\rho}\)</span> is the population correlation of <span class="math inline">\(y\)</span> and <span class="math inline">\(\rho\)</span>.</p>
<p>As the stochastic view highlights, nonresponse bias decreases with increasing <span class="math inline">\(\bar{\rho}\)</span> (which corresponds to the response rate), decreasing correlation of <span class="math inline">\(Y\)</span> and <span class="math inline">\(\rho\)</span>, and decreasing standard deviations of both <span class="math inline">\(\rho\)</span> and <span class="math inline">\(y\)</span>. If <span class="math inline">\(Cor(y, \rho) = 0\)</span>, i.e., if the nonresponse mechanism is not related to <span class="math inline">\(Y\)</span> at all, no nonresponse bias is to be expected. The same is true if <span class="math inline">\(\sigma_{\rho}= 0\)</span> (all individuals have the same propensity to respond) or <span class="math inline">\(\sigma_y = 0\)</span> (all individuals have the same value of <span class="math inline">\(Y\)</span>).</p>
</section>
<section id="why-is-the-response-rate-alone-not-a-reliable-indicator-of-nonresponse-bias" class="level2">
<h2 data-anchor-id="why-is-the-response-rate-alone-not-a-reliable-indicator-of-nonresponse-bias">2.3 Why is the response rate alone not a reliable indicator of nonresponse bias?</h2>
<p>Surveys often report the response rate as an indicator for the quality of the survey. As can be seen from the formulas above, the response rate is part of the deterministic and stochastic perspective on nonresponse bias. Keeping the other factors constant, nonresponse bias is lower the higher the response rate is. There is, however, no clear relationship between the response rate of a survey and the other factors that constitute nonresponse bias. The response rate alone does not allow for an evaluation of nonresponse bias and is thus not a good nonresponse bias indicator <span class="citation" data-cites="groves2006nonresponse groves2008impact">(for empirical findings see for example <a href="#ref-groves2006nonresponse" role="doc-biblioref">Groves, 2006</a>; <a href="#ref-groves2008impact" role="doc-biblioref">Groves &amp; Peytcheva, 2008</a>)</span>.</p>
</section>
</section>
<section id="nonresponse-bias-analysis" class="level1">
<h1>3. Nonresponse bias analysis</h1>
<p>Many methods to examine nonresponse bias have been developed based on Equations (1) to (3). There are too many methods available to be covered in this survey guideline. Thus, the following sections focus on the most frequently used ones.</p>
<p>When conducting nonresponse bias analysis, we need to estimate some of the components of the indicators that have been introduced above. In the survey methodological literature, the term representativeness is widely used to describe the quality of a survey. Representativeness is, however, not clearly defined and may address many different aspects. Focusing on nonresponse bias and assuming random sampling in this guideline, we will call a survey representative if it is not subject to nonresponse bias.</p>
<section id="components-of-nonresponse-bias-analysis" class="level2">
<h2 data-anchor-id="components-of-nonresponse-bias-analysis">3.1 Components of nonresponse bias analysis</h2>
<p>Many of the parameters discussed in Equations (1) to (3) are not known but can be estimated based on the survey information. The mean of the respondents can be estimated by the survey mean <span class="math inline">\(\hat{\bar{y}} = \frac{1}{n} \sum_{i=1}^n y_i\)</span> where <span class="math inline">\(y_i\)</span> (<span class="math inline">\(i = 1, \ldots, n\)</span>) is the survey value for the <span class="math inline">\(i^{th}\)</span> respondent. The response propensity of the invited individuals <span class="math inline">\(\rho\)</span> is not known. In many cases, auxiliary variables <span class="math inline">\(X\)</span> are available for respondents and nonrespondents that can be used to estimate the response propensity. They might be available from the sample frame (e.g., age and gender from official registers), administrative data, paradata from the sampling or recruitment process or, in the panel context, be survey answers from previous survey waves. To estimate the response propensity <span class="math inline">\(\rho\)</span>, the participation indicator R (R=1 if the individual responds to the survey and zero otherwise) is regressed on multiple (<span class="math inline">\(v\)</span>) <span class="math inline">\(X\)</span>-variables, commonly using logistic regression such as</p>
<p><span class="math display">\[
\begin{align}
\hat{\rho_i}= P(R_i=1) = \frac{exp(\hat{\beta}_0 + \hat{\beta}_1
x_{i1}+ \ldots + \hat{\beta}_p x_{iv}) }{1 + exp(\hat{\beta}_0 + \hat{\beta}_1
x_{i1} + \ldots + \hat{\beta}_p x_{iv})}
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\hat{\rho}_i\)</span> is the estimated response propensity for the <span class="math inline">\(i^{th}\)</span> individual, <span class="math inline">\(i = 1 \ldots N\)</span> (the full sample), <span class="math inline">\(\hat{\beta}_0\)</span> is the intercept and <span class="math inline">\(\hat{\beta}_1 \ldots \hat{\beta}_v\)</span> are the slopes for the observed auxiliary variables <span class="math inline">\(X_1 \ldots X_v\)</span>; <span class="math inline">\(x_{i1} \ldots x_{iv}\)</span> are the values of the <span class="math inline">\(X\)</span>-variables of individual <span class="math inline">\(i\)</span>. For large data sets, machine learning methods might be preferred over standard logistic regression, see for example <span class="citation" data-cites="felderer2023using">Felderer et al. (<a href="#ref-felderer2023using" role="doc-biblioref">2023</a>)</span>.</p>
<p>The population parameter <span class="math inline">\(\bar{y}_p\)</span> is usually not known – that is why we conduct the survey in the first place – and can not be estimated from the survey. The same is true for the parameters <span class="math inline">\(\bar{y}_S\)</span> and <span class="math inline">\(\bar{y}_{NR}\)</span>.</p>
<p>There are several indicators available to evaluate the risk of nonresponse bias that can be roughly put into two categories: Indicators that refer to the risk of nonresponse bias of a whole survey and indicators that focus on specific survey variables. For the latter, one can distinguish indicators that basically refer to auxiliary variables and indicators that refer to the variable of interest.</p>
<p>Nonresponse bias as introduced above can usually only be estimated for <span class="math inline">\(X\)</span>-variables that are known for respondents and nonrespondents or for which population benchmarks are available. The <span class="math inline">\(Y\)</span>-variable is usually unobserved for the nonrespondents and lacks a population benchmark. We thus can not study <em>nonresponse bias</em> in the <span class="math inline">\(Y\)</span>-variable directly but rather the <em>risk of nonresponse bias</em> that we derive from knowledge about nonresponse bias in the <span class="math inline">\(X\)</span>-variables and the relation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>Many indicators that we introduce in the following section are generated to apporach nonresponse bias in different ways refering to single aspects of equation (3). They consequently do not estimate nonresponse bias in the strict sense but rather the risk of nonresponse bias (in <span class="math inline">\(X\)</span> or in <span class="math inline">\(Y\)</span>).</p>
</section>
<section id="multivariate-nonresponse-bias-indicators" class="level2">
<h2 data-anchor-id="multivariate-nonresponse-bias-indicators">3.2 Multivariate nonresponse bias indicators</h2>
<p>Several measures for the risk of nonresponse bias have been developed that are based on auxiliary information on respondents and nonrespondents. At their essence, these measures attempt to estimate the extent to which individuals in the survey resemble those in the gross sample or population with respect to the auxiliary <span class="math inline">\(X\)</span>- variables. These results are then used to infer possible bias in the <span class="math inline">\(Y\)</span>- variables of interest. The usefulness of the indicators to evaluate the risk of nonresponse bias in a specific variable of interest heavily depends on the association of this variable and the auxiliary variables. If both variables are not related at all, nonresponse bias in <span class="math inline">\(X\)</span> is not a good indicator for nonresponse bias in <span class="math inline">\(Y\)</span>. The stronger the variables are related, the more we expect <span class="math inline">\(Y\)</span> to show nonresponse bias if <span class="math inline">\(X\)</span> does. The following indicators are multivariate in a way that they account for several auxiliary variables and their relationships in preducing survey nonresponse. Two of them allow to analyse the effect of nonresponse on specific survey variables of interest. The interpretation of the multivariate nonresponse bias indicators is limited to the specific auxiliary variables that they are built on. An excellent comparison of indicators for the risk of nonresponse bias can be found in <span class="citation" data-cites="wagner2012comparison">Wagner (<a href="#ref-wagner2012comparison" role="doc-biblioref">2012</a>)</span>.</p>
<section id="r-indicator" class="level3">
<h3 data-anchor-id="r-indicator">R-indicator</h3>
<p>The R-indicator <span class="math inline">\(R(\rho)\)</span> <span class="citation" data-cites="schouten2009indicators">(<a href="#ref-schouten2009indicators" role="doc-biblioref">Schouten et al., 2009</a>)</span> takes the variation of the response propensity <span class="math inline">\(\rho\)</span> as a measure for the risk of nonresponse bias. With <span class="math inline">\(\sigma_\rho\)</span> being the population standard deviation of <span class="math inline">\({\rho}\)</span>, the R-indicator is given by:</p>
<p><span class="math display">\[
\begin{equation}
R(\rho) = 1 - 2 \sigma_\rho
\end{equation}
\]</span></p>
<p>The R-indicator can take values between 0 and 1. If all sampled individuals have the same propensity to respond, the standard deviation of the response propensities <span class="math inline">\(\sigma_\rho\)</span> is 0 and the R-indicator takes the value of 1. This means that the survey is perfectly “representative”. The R- indicator is zero if <span class="math inline">\(\sigma_\rho= 0.5\)</span> which is the highest value <span class="math inline">\(\sigma_\rho\)</span> can take. This means that the response propensities are very different and the risk of nonresponse bias is high. Only if the auxiliary variables are correlated with both <span class="math inline">\(\rho\)</span> and the variable of interest, the R-indicator can give a good impression on the risk of nonresponse bias in the variable of interest.</p>
<p>In practical applications, the R-indicator can be estimated by <span class="math inline">\(\hat{R}(\hat{\rho}) = 1 - 2 \hat{\sigma}_{\hat{\rho}}\)</span> where <span class="math inline">\(\hat{\rho_i}\)</span> are the estimated response propensities based on auxiliary information as described in Equation (4). Its standard deviation is estimated by <span class="math inline">\(\hat{\sigma}_{\hat{\rho}} = \frac{1}{N} \sum_{i=1}^n (\hat{\rho}_i - \hat{\bar{\rho}})^2\)</span> where <span class="math inline">\(\hat{\rho}_i\)</span> is the estimated response propensity for the <span class="math inline">\(i^{th}\)</span> individual and <span class="math inline">\(\hat{\bar{\rho}}\)</span> is the mean of the estimated propensities.</p>
<p>The R-indicator gives an impression whether the different population subgroups, characterized by a combination of <span class="math inline">\(X\)</span>-variables, are well represented in the survey. The R-indicator does not allow to determine how the individual auxiliary variables that are used to estimate the R-indicator contribute to representativeness. Partial R-indicators have been developed to overcome this limitation <span class="citation" data-cites="schouten2010indicators">(<a href="#ref-schouten2010indicators" role="doc-biblioref">Schouten et al., 2010</a>)</span>.</p>
<p>As for all multivariate nonresponse bias indicators, the usefulness of the R-indicator depends on the auxiliary variables that are used to estimate <span class="math inline">\(\hat{\rho}\)</span>. The R-indicator can only be interpreted with regard to the auxiliary information that it builds on <span class="citation" data-cites="roberts2020validation">(see for example <a href="#ref-roberts2020validation" role="doc-biblioref">Roberts et al., 2020</a>)</span>. R-Indicators are frequently used to compare different (sub)-samples. Comparisons of R-Indicators are only meaningful if the R-indicators are build in the exact same way including the same auxiliary variables. Higher values of the R-indicators indicate better representativeness. However, there is no agreement in the literature on the threshold value above which one can speak of good representativeness. As a guide, an R-indicator of <span class="math inline">\(0.7\)</span> is considered to be rather low <span class="citation" data-cites="lugtig2022nonresponse">(<a href="#ref-lugtig2022nonresponse" role="doc-biblioref">Lugtig et al., 2022</a>)</span>.</p>
</section>
<section id="goodness-of-fit-of-the-propensity-model" class="level3">
<h3 data-anchor-id="goodness-of-fit-of-the-propensity-model">Goodness of fit of the propensity model</h3>
<p>The propensity model for <span class="math inline">\(\hat{\rho_i}\)</span> (see Equation (4)) can be further analysed. The coefficients of the <span class="math inline">\(X\)</span>-variables allow for an interpretation of which variables influence the response propensity. If the response propensity does not depend on <span class="math inline">\(X\)</span>-variables, we expect all coefficients to be insignificant and close to zero. Measures for the goodness of fit of the propensity model, like the (pseudo) <span class="math inline">\(R^2\)</span> or the area under the curve (AUC) are taken as indicators for the risk of nonresponse bias <span class="citation" data-cites="groves2008issues">(see for example <a href="#ref-groves2008issues" role="doc-biblioref">Groves et al., 2008</a>)</span>. Higher values in these measures means that more variation in <span class="math inline">\(\hat{\rho}\)</span> can be explained by the <span class="math inline">\(X\)</span>-variables. This means that respondents and nonrespondents differ for their values of <span class="math inline">\(X\)</span>. A higher goodness of fit of the propensity model thus is taken as an indicator for a higher risk of nonresponse bias in estimates of the variable of interest.</p>
<p>Like the R-indicator, the goodness of fit of the propensity model, however, is only a good indicator for the risk of nonresponse bias in the variable of interest if this variable is associated with <span class="math inline">\(X\)</span>. Finding that the <em>observed</em> <span class="math inline">\(X\)</span>-variables that are included in the propensity model do not explain variation in <span class="math inline">\(\hat{\rho}\)</span> does, on the other side, not necessarily mean that the risk of nonresponse bias is low as there may exist <em>unobserved</em> variables that systematically affect nonresponse.</p>
</section>
<section id="variation-of-nonresponse-weights" class="level3">
<h3 data-anchor-id="variation-of-nonresponse-weights">Variation of nonresponse weights</h3>
<p>Propensity models like in Equation (4) can be used to create adjustment/nonresponse weights by taking the inverse of the estimated response propensity (<span class="math inline">\(1/ \hat{\rho}_i\)</span>) <span class="citation" data-cites="little1986survey">(<a href="#ref-little1986survey" role="doc-biblioref">Little, 1986</a>)</span>. The rough idea behind adjustment methods is to give the groups of respondents who have a lower propensity to respond to the survey (given <span class="math inline">\(X\)</span>-variables) a higher weight in the analysis of the survey data.</p>
<p>The variance of nonresponse weights can be taken as an indicator for the risk of nonresponse bias <span class="citation" data-cites="groves2008issues">(<a href="#ref-groves2008issues" role="doc-biblioref">Groves et al., 2008</a>)</span>: If all individuals have the same propensity to respond, the variance of the nonresponse weights is zero. The higher the variance is, the larger are the differences in the response propensities and the higher the risk of nonresponse bias. This sort of analysis can be conducted for other kinds of nonresponse weighting methods as well and is not limited to propensity weights. Of course, the limitations concerning the relations between <span class="math inline">\(X\)</span>-variables and <span class="math inline">\(Y\)</span> that we discussed above also hold for this and other multivariate nonresponse bias indicators.</p>
</section>
<section id="correlation-between-nonresponse-weights-and-y" class="level3">
<h3 data-anchor-id="correlation-between-nonresponse-weights-and-y">Correlation between nonresponse weights and <span class="math inline">\(Y\)</span></h3>
<p>The correlation between the nonresponse weights and observed <span class="math inline">\(Y\)</span> is an attempt to estimate the association of the auxiliary variables and the response propensity and <span class="math inline">\(Y\)</span> <span class="citation" data-cites="groves2008issues">(<a href="#ref-groves2008issues" role="doc-biblioref">Groves et al., 2008</a>)</span>. The association can only be estimated for respondents and relies on the assumption that the association is the same for respondents and the full sample. A higher correlation between nonresponse weights and <span class="math inline">\(Y\)</span> indicates a higher risk of nonresponse bias. In this case, we will also observe differences between weighted and unweighted means and proportions of <span class="math inline">\(Y\)</span> (see <span class="citation" data-cites="Gabler2015">Gabler et al. (<a href="#ref-Gabler2015" role="doc-biblioref">2015</a>)</span> and <span class="citation" data-cites="Sand2020">Sand &amp; Kunz (<a href="#ref-Sand2020" role="doc-biblioref">2020</a>)</span> on the theoretical background and application on different kinds of nonresponse weights). The correlation between nonresponse weights and <span class="math inline">\(Y\)</span> is an indicator for nonresponse bias <em>before</em> weighting adjustment. It does not allow any conclusions about nonresponse bias of the adjusted statistics or the usefulness of the weights. The correlation between nonresponse weights and <span class="math inline">\(Y\)</span> is only a meaningful indicator for nonresponse bias under the MAR-assumption.</p>
</section>
<section id="fraction-of-missing-information" class="level3">
<h3 data-anchor-id="fraction-of-missing-information">Fraction of missing information</h3>
<p>The fraction of missing information (FMI) was developed in the multiple imputation context <span class="citation" data-cites="rubin1987multiple">(see <a href="#ref-rubin1987multiple" role="doc-biblioref">Rubin, 1987</a>)</span> dealing with item nonresponse and has been transferred to unit nonresponse bias analysis <span class="citation" data-cites="wagner2010fraction">(<a href="#ref-wagner2010fraction" role="doc-biblioref">Wagner, 2010</a>)</span>. In the context of unit nonresponse, the missing survey information of nonrespondents is imputed using auxiliary data that is available for respondents and nonrespondents. The idea is to take the level of uncertainty when imputing the missing values for the variable of interest <span class="math inline">\(Y\)</span> based on auxiliary (complete) <span class="math inline">\(X\)</span> as an indicator for nonresponse bias. For the FMI, the missing observations in the <span class="math inline">\(Y\)</span>-variables are imputed multiple (<span class="math inline">\(M\)</span>) times. The mean or proportion of <span class="math inline">\(Y\)</span> is then estimated based on the fully imputed data set (including observed values for respondents and imputed values for nonrespondents) for each imputation round <span class="math inline">\(m\)</span>.</p>
<p>With <span class="math inline">\(M\)</span> imputations for each missing value, <span class="math inline">\(\bar{y}\)</span> is estimated by <span class="math inline">\(\hat{\bar{y}}_M = \sum_{m=1}^M \hat{\bar{y}}_m /M\)</span> where <span class="math inline">\(\hat{\bar{y}}_m\)</span> is the estimated mean in the <span class="math inline">\(m_{th}\)</span> imputed data set. The FMI gives a measure of uncertainty about the imputed values by computing the relation between the between-imputation variance and the total variance of <span class="math inline">\(\hat{\bar{y}}_M\)</span>. Let <span class="math inline">\({Var}_m(\hat{\bar{y}}_m)\)</span> be the variance of <span class="math inline">\(\hat{\bar{y}}_m\)</span> in the <span class="math inline">\(m_{th}\)</span> imputed data set. The within-imputation variance is given by <span class="math inline">\(Var_W(\hat{\bar{y}}_M)= \sum_{m=1}^M Var_m(\hat{\bar{y}}_m)/M\)</span>. The within-imputation variance describes the variance that is due to sampling. The between-imputation variance is given by <span class="math inline">\(Var_B(\hat{\bar{y}}_M) = \frac{\sum_{m=1}^M (\hat{\bar{y}}_m - \hat{\bar{y}}_M)^2}{(M-1)}\)</span> and is the part of variation that is due to imputation uncertainty. The total variance is given by <span class="math inline">\(Var(\hat{\bar{y}}_M) = Var_W(\hat{\bar{y}}_M) + (M+1) M^{-1} Var_B(\hat{\bar{y}}_M)\)</span>.</p>
<p>The FMI is given as the ratio of the between-imputation and total variance and is estimated as</p>
<p><span class="math display">\[
\begin{equation}
\widehat{FMI} = \frac{(1+\frac{1}{M})
Var_B(\hat{\bar{y}}_M)}{Var(\hat{\bar{y}}_M)}
\end{equation}
\]</span></p>
<p>The FMI ranges from 0 to 1 and can be interpreted as the proportion of variation in the estimation of <span class="math inline">\(\bar{y}\)</span> that is due to the missing data. The higher the uncertainty about the values of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, the more different are the imputed values between the imputation rounds and the higher is the between-imputation variance. Or, in other words, if the data includes good predictors for <span class="math inline">\(Y\)</span>, the between-imputation variance decreases (<span class="citation" data-cites="rubin1987multiple">Rubin (<a href="#ref-rubin1987multiple" role="doc-biblioref">1987</a>)</span>). A larger <span class="math inline">\(\hat{FMI}\)</span> is thus interpreted to indicate a higher risk of nonresponse bias in the estimation of <span class="math inline">\(\hat{\bar{y}}\)</span> caused by other variables than included in the imputation process.</p>
<p>If the imputation model perfectly explains <span class="math inline">\(Y\)</span>, there are no differences expected between the imputation rounds and the between-imputation variance is close to zero. As <span class="citation" data-cites="wagner2010fraction">Wagner (<a href="#ref-wagner2010fraction" role="doc-biblioref">2010</a>)</span> shows, for correctly specified imputation models, the FMI is close to the nonresponse rate if <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are only weakly correlated and moves toward zero as the correlation increases. Highly correlated <span class="math inline">\(X\)</span> variables can thus recover the missing information in <span class="math inline">\(Y\)</span>.</p>
<p>As <span class="citation" data-cites="andridge2011proxy">Andridge &amp; Little (<a href="#ref-andridge2011proxy" role="doc-biblioref">2011</a>)</span> note the FMI has the disadvantage to focus more on precision than on bias and is limited to MAR situations. The FMI also depends on the imputation methods and the specification of the imputation model <span class="citation" data-cites="wagner2010fraction">(<a href="#ref-wagner2010fraction" role="doc-biblioref">Wagner, 2010</a>)</span>.</p>
</section>
</section>
<section id="univariate-nonresponse-bias-indicators" class="level2">
<h2 data-anchor-id="univariate-nonresponse-bias-indicators">3.3 Univariate nonresponse bias indicators</h2>
<p>The multivariate nonresponse bias indicators introduced in the previous section are measures including several <span class="math inline">\(X\)</span>-variables and their relationships. With the exception of the interpretation of the coefficients of the nonresponse propensity model, they do not allow for an interpretation which specific <span class="math inline">\(X\)</span> variables contribute to bias and in which direction. Although it is possible to run nonresponse models with just a single variable and use this model to estimate the nonresponse bias indicators discussed in the previous section, other methods are better suited to look at the effects of individual variables. Such univariate nonresponse bias indicators give more detailed information on nonresponse bias of certain variables and can be used to evaluate which of the auxiliary variables affect the risk of nonresponse bias in the variables of interest. This is done by comparing respondents to official population benchmarks or respondents to nonrespondents for these auxiliary variables. Univariate nonresponse bias indicators do not account for the interplay of different auxiliary variables. Like the nonresponse bias indicators discussed in the previous section, univariate nonresponse bias indicators are only useful under the assumption that the auxiliary variables are related to the variable of interest.</p>
<section id="benchmark-comparisons" class="level3">
<h3 data-anchor-id="benchmark-comparisons">Benchmark comparisons</h3>
<p>One way to evaluate nonresponse bias is to compare survey findings to benchmarks from official statistics for the general population <span class="citation" data-cites="felderer2019effect Rohr2023">(see for example <a href="#ref-felderer2019effect" role="doc-biblioref">Felderer et al., 2019</a>; <a href="#ref-Rohr2023" role="doc-biblioref">Rohr et al., 2023</a>)</span>. For surveys on the German population, the distribution of socio-demographic characteristics among the respondents to a survey might, for example, be compared to official statistics like the <a href="https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Bevoelkerung/Haushalte-Familien/Methoden/mikrozensus.html"></a> or to a high-quality survey of the German population like the <a href="https://www.gesis.org/allbus/allbus"></a>. If the survey respondents are similar to the general population, the risk of nonresponse bias is assumed to be low. Benchmark comparisons thereby implicitly rely on the assumption that the survey estimate <span class="math inline">\(\hat{\bar{x}}\)</span> is not subject to bias apart from nonresponse. Other sources of bias like sampling or coverage error are neglected. The advantage of benchmark comparisons is that no information on nonrespondents are needed. However, the number of variables that can be compared against benchmarks is usually rather limited. Usually, no benchmarks are available for the variables of interest <span class="math inline">\(Y\)</span>.</p>
<p>Let <span class="math inline">\(\hat{\bar{x}}\)</span> be the survey mean and <span class="math inline">\(\bar{x}_{bench}\)</span> the population benchmark for the auxiliary variables. To be able to compare nonresponse bias over variables and between surveys, the relative nonresponse bias for a variable <span class="math inline">\(x_j\)</span> is estimated as</p>
<p><span class="math display">\[
\begin{equation}
\widehat{rel. Bias}(\bar{x}_j) = \frac{\hat{\bar{x_j}} -
\bar{x_j}_{bench}}{\bar{x_j}_{bench}}.
\end{equation}
\]</span></p>
<p>In practice, the differences between <span class="math inline">\(\hat{\bar{x}}\)</span> and <span class="math inline">\(\bar{x}_{bench}\)</span> will be non-zero due to random sampling variation. Appropriate statistical tests can be performed to evaluate statistical significance of the differences <span class="citation" data-cites="Eckman2022 felderer2019effect">(see for example <a href="#ref-Eckman2022" role="doc-biblioref">Eckman et al., 2022</a>; <a href="#ref-felderer2019effect" role="doc-biblioref">Felderer et al., 2019</a>)</span>.</p>
<p>In practical applications, the relative biases are often estimated for a number of available auxiliary variables. All relative biases might be aggregated to one single measure that can be compared across surveys or experimental subgroups of a survey. A commonly reported measure is the average absolute relative bias (AARB) <span class="citation" data-cites="cornesse2021recruiting friedel2023early">(see for example <a href="#ref-cornesse2021recruiting" role="doc-biblioref">Cornesse et al., 2021</a>; <a href="#ref-friedel2023early" role="doc-biblioref">Friedel et al., 2023</a>)</span> which is given by the mean of the absolute relative biases. The absolute values are taken to make sure that negative and positive relative biases do not cancel each other out. For <span class="math inline">\(v\)</span> auxiliary variables the AARB is given by</p>
<p><span class="math display">\[
\begin{equation}
\widehat{AARB} = \frac{1}{v} \sum_{j=1}^v \left|\frac{\bar{x}_{j} -
\bar{x}_{bench_j}}{\bar{x}_{bench_j}}\right|
\end{equation}
\]</span></p>
<p>with subscripts <span class="math inline">\(j = 1 \ldots v\)</span> indicating the <span class="math inline">\(j^{th}\)</span> <span class="math inline">\(X\)</span>-variable. Relative biases can also be aggregated to median absolute relative bias and the maximum absolute relative bias. These aggregated measures have the advantage to reduce the findings for several <span class="math inline">\(X\)</span>-variables to one single value but they are not a multivariate indicator in our sense as they do not account for the interplay of different <span class="math inline">\(X\)</span>-variables. As they do not allow to identify the contribution of the individual characteristics, we recommend to not only analyse the aggregate measures but also their single components.</p>
<p>The AARB is not standardized and its interpretation is only meaningful in comparison to relative biases found in other surveys or for experimental subgroups of the same survey. In order to meaningfully compare AARBs between surveys, one needs to make sure that the same set of auxiliary variables (that are measured and coded in the same way) are included in the analysis. High nonresponse bias in the auxiliary variables might indicate a high risk of nonresponse bias in the variables of interest. If both kinds of variables are not correlated, even high nonresponse bias in auxiliary variables is no indication of nonresponse bias in the survey variables of interest.</p>
<p>Other measures that are based on benchmark comparisons are the Duncan dissimilarity index <span class="citation" data-cites="bosnjak2018establishing">(for example <a href="#ref-bosnjak2018establishing" role="doc-biblioref">Bosnjak et al., 2018</a>)</span> and absolute difference or standardized absolute difference <span class="citation" data-cites="peytcheva2009using">(for example <a href="#ref-peytcheva2009using" role="doc-biblioref">Peytcheva &amp; Groves, 2009</a>)</span>.</p>
</section>
<section id="comparison-of-respondents-and-nonrespondents-on-auxiliary-variables" class="level3">
<h3 data-anchor-id="comparison-of-respondents-and-nonrespondents-on-auxiliary-variables">Comparison of respondents and nonrespondents on auxiliary variables</h3>
<p>Usually,the number of survey variables that can be compared to official statistics is very limited. In many applications, however, auxiliary variables <span class="math inline">\(X\)</span> from the sample frame, paradata from the fieldwork process <span class="citation" data-cites="krueger2014assessing">(for example <a href="#ref-krueger2014assessing" role="doc-biblioref">Krueger &amp; West, 2014</a>)</span> or, in a panel context, survey information from previous waves are available for all individuals who are invited to participate in a survey. Comparisons between respondents and nonrespondents can be performed by comparing means and proportions and determining significance using appropriate statistical tests.</p>
</section>
<section id="comparison-of-early-and-late-respondents" class="level3">
<h3 data-anchor-id="comparison-of-early-and-late-respondents">Comparison of early and late respondents</h3>
<p>A comparison of early or “easy-to-contact” respondents to late or “hard-to-contact” respondents is sometimes used to get an impression of the risk of nonresponse bias <span class="citation" data-cites="green1991reluctant">(see for example <a href="#ref-green1991reluctant" role="doc-biblioref">Green, 1991</a>)</span>. Doing this, the late respondents are assumed to be similar to nonrespondents. While this approach relies on strong assumptions, it has the advantage that it can be performed on auxiliary variables as well as the survey variables of interest. To receive information on nonrespondents, sometimes a nonresponse follow-up survey <span class="citation" data-cites="roberts2020validation">(see for example <a href="#ref-roberts2020validation" role="doc-biblioref">Roberts et al., 2020</a>)</span> is conducted using a shortened questionnaire. The respondents to the main survey are then compared to the respondents of the nonresponse follow-up survey assuming that the latter are representative of all nonrespondents to the main survey.</p>
</section>
<section id="variation-of-subgroup-response-rates" class="level3">
<h3 data-anchor-id="variation-of-subgroup-response-rates">Variation of subgroup response rates</h3>
<p>The evaluation of the variation of subgroup response rates is a univariate indicator that follows the same idea as the (multivariate) evaluation of the goodness of fit and nonresponse weights <span class="citation" data-cites="wagner2012comparison">(see for example <a href="#ref-wagner2012comparison" role="doc-biblioref">Wagner, 2012</a>)</span>. If different subgroups (defined by the categories of a specific auxiliary variable) show different response rates, this is taken as an indication for an increased risk of nonresponse bias in the survey variable of interest. For a categorical variable with <span class="math inline">\(c\)</span> categories the subgroup response rates are given as <span class="math inline">\(RR_{sub, c} = \frac{n_c}{N_c}\)</span> where <span class="math inline">\(n_c\)</span> is the number of respondents in category <span class="math inline">\(c\)</span> and <span class="math inline">\(N_c\)</span> the number of sampled persons in category <span class="math inline">\(c\)</span>. <span class="math inline">\(RR_{sub}\)</span> is the vector of the subgroup response rates for all categories of a specific variables. The variance of subgroup response rates can be estimated by:</p>
<p><span class="math display">\[
\begin{equation}
\hat{Var}(RR_{sub}) = \frac{1}{N-1} \sum_{c=1}^C N_c
(\frac{n_c}{N_c} - \frac{n}{N})^2
\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\frac{n}{N}\)</span> is the survey’s response rate. The subgroup response rate does not require information on nonrespondents on an individual level but only sample (or population) proportions of the auxiliary variable. To standardize subgroup response rates, the coefficient of variation of the subgroup response rates <span class="citation" data-cites="nishimura2016alternative">(see for example <a href="#ref-nishimura2016alternative" role="doc-biblioref">Nishimura et al., 2016</a>)</span> can be calculated as</p>
<p><span class="math display">\[
\begin{equation}
\hat{CV}(RR_{sub}) =  \frac{\hat{Var}(RR_{sub})}{n/N}.
\end{equation}
\]</span></p>
<p>Higher values of <span class="math inline">\(\hat{CV}(RR_{sub})\)</span> are taken as a higher risk of nonresponse bias. <span class="math inline">\(\hat{Var}(RR_{sub})\)</span> is only a useful indicator if <span class="math inline">\(X\)</span> is associated with <span class="math inline">\(Y\)</span>.</p>
</section>
</section>
</section>
<section id="illustration-of-use-of-nonresponse-bias-indicators" class="level1">
<h1>4. Illustration of use of nonresponse bias indicators</h1>
<p>To illustrate the use of the measures described above, we apply them to synthetic data sets that are generated to match the three nonresponse mechanisms discussed in section 2.1. The approach was strongly inspired by <span class="citation" data-cites="nishimura2016alternative">Nishimura et al. (<a href="#ref-nishimura2016alternative" role="doc-biblioref">2016</a>)</span>. The details of the synthetic data example set up can be found in the attached R-script. We create five <span class="math inline">\(X\)</span>-variables and one <span class="math inline">\(Y\)</span>-variable (<span class="math inline">\(Y_1, Y_2, Y_3\)</span>) for each mechanism. The <span class="math inline">\(X\)</span>-variables are generated to match the distribution in the German population according to the Mikrozensus 2019. The response mechanism roughly mimics typical findings for <em>age, gender, education, household size</em> and <em>German nationality</em>. For example, sampled individuals who are highly educated participate more often than the less educated ones. Lastly, a variable <span class="math inline">\(Z\)</span> is generated that can be seen as an unobserved variable that is related to <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_3\)</span>. A random error term is added to the generation of all <span class="math inline">\(Y\)</span>- variables and response propensities to avoid perfect relations between them and <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>.</p>
<p>For the <em>separate cause model</em>, the response propensity is generated to be a function of all <span class="math inline">\(X\)</span>-variables (<span class="math inline">\(\rho = f(X_1, \ldots, X_5)\)</span>) while <span class="math inline">\(Y_1\)</span> is a function of one <span class="math inline">\(Z\)</span>-variable and does not depend on any <span class="math inline">\(X\)</span> (<span class="math inline">\(Y_1=f(Z)\)</span>).</p>
<p>For the <em>common cause model</em>, the response propensity is again a function of all <span class="math inline">\(X\)</span>-variables. The variable <span class="math inline">\(Y_2\)</span> is a function of three of the five <span class="math inline">\(X\)</span>-variables (<span class="math inline">\(Y_2 = f(X_1, X_2, X_3)\)</span>) which resemble gender, age and education.</p>
<p>For the <em>survey variable cause model</em>, neither <span class="math inline">\(Y_3\)</span> nor the response propensity depend on the <span class="math inline">\(X\)</span>-variables. <span class="math inline">\(Y_3\)</span> depends on variable <span class="math inline">\(Z\)</span> (<span class="math inline">\(Y_3=f(Z)\)</span>) and the response propensity is associated with the survey variable of interest (<span class="math inline">\(\rho = f(Y_3)\)</span>).</p>
<p>For each scenario, samples of size <span class="math inline">\(N=2000\)</span> are generated with response rates of 50%. All individuals who have a response propensity above the median response rate are considered respondents to the survey. As nonresponse depends on the same set of variables in the <em>separate cause model</em> example and the <em>common cause model</em> example <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> can be interpreted as being collected in the same survey. The variable <span class="math inline">\(Y_3\)</span> is assumed to be from a different survey with a different response mechanism.</p>
<p>The example is kept very simple and relationships are, of course, more complex in reality. For example, even in the <em>survey variable cause model</em> <span class="math inline">\(Y\)</span> may depend on <span class="math inline">\(X\)</span>. Moreover, many <span class="math inline">\(X\)</span>-variables that affect <span class="math inline">\(\rho\)</span> are usually not observed and/or not known or show missing values.</p>
<section id="multivariate-nonresponse-bias-indicators-1" class="level2">
<h2 data-anchor-id="multivariate-nonresponse-bias-indicators-1">4.1 Multivariate nonresponse bias indicators</h2>
<p>Let us consider two scenarios. In our first scenario, we have information on all five socio-demographic variables in our studies from the sample frame and use these information to conduct nonresponse bias analysis. In our second and more realistic scenario, some variables that affect nonresponse are not available from the frame and we only have a subset of the socio-demographic variables, gender, age and German citizenship, limiting our analysis to these variables.</p>
<p>To estimate multivariate nonresponse bias indicators, we run a logistic regression of the response indicator (yes/no) on all available frame information in each scenario. We estimate the R-indicator using the predicted probabilities from the logistic regression and build nonresponse weights as the inverse of the predicted probabilities. Table <span class="math inline">\(\ref{tab1}\)</span> shows the R-indicator, McFadden’s pseudo <span class="math inline">\(R^2\)</span> from the logistic regression and the variance of the nonresponse weights.</p>
<p>The measures in the first three columns make use of all variables that are part of the nonresponse process for the <em>separate cause model</em> and the <em>common cause model</em>. The limited variable set used in the second scenario does not include all relevant variables. None of the variables used in any scenario affect the nonresponse process for the <em>survey variable cause model</em>.</p>
<p>The indicators need to be interpreted with caution and we must be aware which conclusions can be drawn and which not. All these measures only indicate to what extent the distributions of the <span class="math inline">\(X\)</span>-variables in the survey correspond to those in the population. For the full variable set scenario, all indicators show very low risk of nonrespnse bias in the survey variable cause model but high risk for the other two models. That is expected, as we know that the data was generated that way. We should, however, not naively conclude that we have a generally low risk of nonresponse bias in this survey. Knowledge of the relationship of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, e.g., empirical evidence from other studies or theoretical considerations can help to judge whether to expect nonresponse bias in <span class="math inline">\(Y\)</span>. If we, for example, know from other studies that the <span class="math inline">\(Y\)</span> variable is highly correlated to the <span class="math inline">\(X\)</span>- variables (like it is the case for <span class="math inline">\(Y_2\)</span>), we would assume a high risk of nonresponse bias in this variable of interest but not for a variable that is not related to <span class="math inline">\(X\)</span>, like <span class="math inline">\(Y_1\)</span> in the same survey. In our example, <span class="math inline">\(Y_3\)</span> is generated to not depend on the <span class="math inline">\(X\)</span>-variables but to <span class="math inline">\(Y_3\)</span> itself. Thus, the indicators are not meaningful when it comes to the risk of nonresponse bias in <span class="math inline">\(Y_3\)</span>. Likewise, there can always exist unknown or unobserved auxiliary variables that are related to <span class="math inline">\(Y\)</span> and cause nonresponse bias. If these variables are not related to the <span class="math inline">\(X\)</span>-variables that might capture parts of their effect, the high risk of nonresponse bias can not be detected. This illustrates the limitations of these indicators: they summarize the representation of different population subgroups (based on the <span class="math inline">\(X\)</span>-variables) but do not allow to rule out effects of variables that are not part of the analysis, either because they can not be compared to some benchmark or are not observed at all.</p>
<p>Comparing the full variable set scenario to the limited variable set scenario, we find all indicators to “improve”: the R-indicators are higher whereas McFadden’s <span class="math inline">\(R^2\)</span> and the variation of the nonresponse weights are closer to zero. These findings show how the specification of the nonresponse model that is part of these three measures influences the results. Interestingly, the mis-specified models in the limited variable set scenario that excludes relevant auxiliary variables misleadingly indicates a lower risk of nonresponse bias. This makes sense as leaving out relevant predictors in the nonresponse model decreases the model fit and thus McFadden’s <span class="math inline">\(R^2\)</span> and decreases the variation of the predicted values for the nonresponse propensity. Again, the indicators can only be interpreted in relation to the specific <span class="math inline">\(X\)</span>-variables. We can never know for sure that there are no unobserved characteristics that are excluded from the estimation of the nonresponse bias indicator (like in the limited variable set scenario) that systematically affect survey nonresponse.</p>
<p>Both scenarios show that the <em>survey variable cause model</em> in our example exhibits higher representativeness (of the <span class="math inline">\(X\)</span>-variables) than the other models. Finding that the indicators heavily depend on the model specification, it is important to note that the indicators should only be compared between surveys if they include the same set of <span class="math inline">\(X\)</span>-variables. Also, they should only be interpreted with respect to the <span class="math inline">\(X\)</span>-variables they make use of. In the full variable set we can draw conclusions about the surveys’ representativeness with regard to gender, age, education, German citizenship and household size whereas in the limited variable set our conclusions are limited to gender, age and German citizenship.</p>
<p>Table <span class="math inline">\(\ref{tab4}\)</span> shows the correlation between nonresponse weights and <span class="math inline">\(Y\)</span> and the FMI in estimating <span class="math inline">\(\hat{\bar{y}}\)</span>. We show the results for the full information and limited information scenario described above. To estimate the FMI, we impute <span class="math inline">\(Y\)</span> using all <span class="math inline">\(X\)</span>-variable values that are available in the respective scenario. We conduct multiple imputations (<span class="math inline">\(m=10\)</span>) using predictive mean matching as implemented in the R package <em>mice</em> <span class="citation" data-cites="VanBuuren2011">(<a href="#ref-VanBuuren2011" role="doc-biblioref">Van Buuren &amp; Groothuis-Oudshoorn, 2011</a>)</span>. The results are shown in Table <span class="math inline">\(\ref{tab4}\)</span>.</p>
<p>Comparing the <em>separate cause model</em> and <em>common cause model</em>, we find that the correlation of weights and <span class="math inline">\(Y\)</span> correctly identifies a higher risk in nonresponse bias for <span class="math inline">\(Y\)</span> in the common cause model for the full variable set scenario. It does, however, not detect the high nonresponse bias in <span class="math inline">\(Y\)</span> in the <em>survey variable cause model</em>. This was expected as there is no relationship between the <span class="math inline">\(X\)</span>-variables and <span class="math inline">\(Y\)</span> for this model. Consequently, findings are very similar for the <em>survey variable cause model</em> and the <em>separate cause model</em> for which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are also not associated. Whereas for the <em>separate cause model</em> we are right to conclude that there is only a low risk of nonresponse bias in <span class="math inline">\(Y\)</span> we would be wrong in the <em>survey variable cause model</em>. For the limited variable set scenario, the correlations are estimated to be of about the same size for all of the three nonresponse models, failing to detect the high risk of nonresponse bias in the <em>common cause model</em>. Again, the nonresponse bias indicators can only be interpreted in relation to the <span class="math inline">\(X\)</span>-variables they are built on and they are not able to detect a correlation of <span class="math inline">\(Y\)</span> and <span class="math inline">\(\rho\)</span> or of <span class="math inline">\(Y\)</span> and unobserved <span class="math inline">\(X\)</span>-variables that are not part of the propensity model.</p>
<p>The FMI can be interpreted by comparing its value to the nonresponse rate. As <span class="citation" data-cites="nishimura2016alternative">Nishimura et al. (<a href="#ref-nishimura2016alternative" role="doc-biblioref">2016</a>)</span> point out, the FMI is bounded by the nonresponse rate under the MAR model. Observing values that are much higher than the nonresponse rate (50 % in our case) is an indication that the imputation model is mis-specified. If the imputation model is correctly specified, the FMI should not be larger than about <span class="math inline">\(0.5\)</span>. The higher the correlation of <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, the stronger the FMI decreases towards zero. For the limited variable set scenario we find all FMIs to be larger than <span class="math inline">\(0.5\)</span> indicating that the models are mis-specified and do not caputure all <span class="math inline">\(X\)</span>-variables that relate to the response propensity. For the full variable set scenario, the FMI is larger than <span class="math inline">\(0.5\)</span> for the <em>separate cause model</em> and <em>survey variable cause model</em>. This again can be explained by the fact that <span class="math inline">\(X\)</span> is not correlated with <span class="math inline">\(Y\)</span> and using <span class="math inline">\(X\)</span> for the imputation for <span class="math inline">\(Y\)</span> has no positive effect on the between-imputation-variance of <span class="math inline">\(Y\)</span>. As noted above, both models do not lead to data that are missing at random and thus do not meet the assumptions of the FMI. We are not able to distinguish between the <em>separate cause</em> and <em>survey variable cause</em> model based on the FMIs. Whereas for the <em>survey variable cause</em> model we are right to conclude that we observe a high risk of nonresponse bias the large FMI in the <em>separate cause model</em> is misleading. The FMI for the <em>common cause model</em> reflects the situation very well. It is lower than the nonresponse rate indicating correct model specification. Due to random error in the generation of <span class="math inline">\(Y\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not perfectly correlated and the FMI is not exactly zero.</p>
<p>The multivariate nonresponse bias indicators are useful measures for the representativeness of a survey regarding the specific variables they are built on. They do, however, not allow for an evaluation of which variables are well represented and which are not. Most importantly, taking them as indicators for the risk of nonresponse bias in <span class="math inline">\(Y\)</span> might be very misleading. The representativeness of <span class="math inline">\(X\)</span> can only be used as an indicator for nonresponse bias in <span class="math inline">\(Y\)</span> under the assumption that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are highly correlated on the population level. This assumption usually cannot be tested. Only substantive knowledge on the relationships between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can help to evaluate whether the assumption holds.</p>
<p>Several indicators that allow for an evaluation of the risk of nonresponse bias on the variable level are illustrated in the following section.</p>
</section>
<section id="univariate-nonresponse-bias-indicators-1" class="level2">
<h2 data-anchor-id="univariate-nonresponse-bias-indicators-1">4.2 Univariate nonresponse bias indicators</h2>
<p>Let us assume we know the means and proportions for the socio-demographics (<span class="math inline">\(X\)</span>-variables) from official statistics such as the Mikrozensus. We can easily compare the survey estimates based on the respondents and the population values from the Mikrozensus for the <span class="math inline">\(X\)</span>-variables for the three nonresponse models. We should be aware, however, that even for random sampling of the individuals, the survey estimates likely do not exactly match the population parameters by chance. Like in real applications, we are not able to separate random sampling error from nonresponse error.</p>
<p>To be able to compare the magnitude of nonresponse bias between <span class="math inline">\(X\)</span>-variables and different surveys, we compute the relative biases using benchmarks from official statistics and the AARB (see Table <span class="math inline">\(\ref{tab3}\)</span>). For illustration, we assume that we also know the true distribution of <span class="math inline">\(Y\)</span> which is usually unknow. This allows us to estimate relative nonresponse bias in <span class="math inline">\(Y\)</span> as well. The relative biases in <span class="math inline">\(X\)</span> are the same for the <em>separate cause model</em> and the <em>common cause model</em> but differ from the ones for the <em>survey variable cause model</em>.</p>
<p>We can, for example, see that the younger age cohorts are under- and the older age cohorts are over-represented for all surveys. The mis-representation is strongest for the individuals aged 16 to 29 years. The AARB gives a summary of the biases and naturally shows the same trend as the indicators from the previous section: the <em>survey variable cause model</em> shows the highest representativeness or, in other words, lowest AARB for the socio-demographic variables under study.</p>
<p>In this example, we are able to evaluate bias in the <span class="math inline">\(Y\)</span>-variables as well. The <em>separate cause model</em> and <em>common cause model</em> examples are generated to be the same survey with different <span class="math inline">\(Y\)</span>-variables of interest. We can see that the <span class="math inline">\(Y\)</span>-variable in the <em>separate cause model</em> example is under-estimated to a very small degree due to random sampling error whereas the <span class="math inline">\(Y\)</span>-variable from the <em>common cause model</em> shows an over-estimation of more than 5%. This shows that variables from the same survey can be affected by nonresponse very differently depending on how they are related to the nonresponse mechanism. In our example, nonresponse bias is highest for the <span class="math inline">\(Y\)</span>-variable from the <em>survey variable cause model</em>. Even though the survey was very representative for all <span class="math inline">\(X\)</span>-variables, <span class="math inline">\(Y\)</span> suffers from severe nonresponse bias. This example shows that a good/bad representation of <span class="math inline">\(X\)</span> does not necessarily imply a good/bad representation of <span class="math inline">\(Y\)</span>. This example made use of the population information of <span class="math inline">\(Y\)</span> which is usually not available.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>5. Conclusion</h1>
<p>Declining participation rates raise concerns of high nonresponse bias. However, as discussed in the previous sections, it is not so much the general willingness to participate that affects the risk of nonresponse bias, but rather how different this willingness is for different population groups. Nonresponse bias arises whenever respondents differ from nonrespondents in the characteristic of interest. Within the same survey, statistics for some variables may be completely accurate and others may be heavily biased. If the nonresponse mechanism depends on the variable of interest, estimates for this variable will be biased no matter how well the other variables are represented.</p>
<p>Since usually nonresponse bias in the variables of interest cannot be measured directly, measures based on auxiliary variables such as socio-demographic characteristics are used to estimate the risk of nonresponse bias. In order to draw conclusions to the variable of interest it is necessary to use auxiliary variables that are correlated to them. In addition to frame information, the collection of interviewer observations and paradata has shown to be useful to study nonresponse bias and to apply nonresponse adjustments <span class="citation" data-cites="krueger2014assessing">(see for example <a href="#ref-krueger2014assessing" role="doc-biblioref">Krueger &amp; West, 2014</a>)</span>.</p>
<p>Indicators that in addition to the auxiliary variables incorporate the variables of interest can be very helpful if the data follow the <em>common cause model</em>. In case of the <em>survey variable cause model</em> or if the nonresponse mechanism is mis-specified, however, they tend to be misleading.</p>
<p>All of the above indicators can provide information about the risk of nonresponse bias, but they have their limitations. Their interpretation should always be guided by considerations of contextual relationships. To get the most accurate picture of nonresponse bias, we highly recommend to use several indicators. The estimation and visualization of many of the proposed nonresponse bias indicators are implemented in the easy to use R package <em>sampcompR</em> <span class="citation" data-cites="sampcompr">(<a href="#ref-sampcompr" role="doc-biblioref">Rohr, 2023</a>)</span>.</p>
<p>We propose to start with estimating the nonresponse model whenever auxiliary information is available for respondents and nonrespondents. Modelling nonresponse requires a clearly defined sample and a response indicator that can be assigned to each unit of the sample. The model coefficients provide information on which characteristics influence participation and in which direction. Estimated response propensities can than be used to estimate several multivariate nonresponse bias indicators.</p>
<p>We propose to compare survey estimates to benchmarks from official statistics on all available characteristics. This is especially useful for all characteristics that are available for respondents only and are thus not available for the nonresponse models. Note that the differences between survey estimates and population benchmarks can only be attributed to nonresponse if the sample is drawn randomly from the population (and design weights are used if applicable) and the measurement is assumed to be error-free. Even if these assumptions are fulfilled, the survey estimate will randomly deviate from the population benchmark due to sampling.</p>
</section>
<section id="references" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-andridge2011proxy" class="csl-entry" role="listitem">
Andridge, R. R., &amp; Little, R. J. (2011). Proxy pattern-mixture analysis for survey nonresponse. <em>Journal of Official Statistics</em>, <em>27</em>(2), 153.
</div>
<div id="ref-bethlehem1988reduction" class="csl-entry" role="listitem">
Bethlehem, J. G. (1988). Reduction of nonresponse bias through regression estimation. <em>Journal of Official Statistics</em>, <em>4</em>(3), 251–260.
</div>
<div id="ref-bosnjak2018establishing" class="csl-entry" role="listitem">
Bosnjak, M., Dannwolf, T., Enderle, T., Schaurer, I., Struminskaya, B., Tanner, A., &amp; Weyandt, K. W. (2018). Establishing an open probability-based mixed-mode panel of the general population in <span>G</span>ermany: The GESIS panel. <em>Social Science Computer Review</em>, <em>36</em>(1), 103–115.
</div>
<div id="ref-Bruch2023" class="csl-entry" role="listitem">
Bruch, C. (2023). Imputation of missing values in survey data. <em>Mannheim, GESIS – Leibniz-Institut Für Sozialwissenschaften (GESIS Survey Guidelines)</em>. <a href="https://doi.org/10.15465/gesis-sg_en_044">https://doi.org/10.15465/gesis-sg_en_044</a>
</div>
<div id="ref-cornesse2021recruiting" class="csl-entry" role="listitem">
Cornesse, C., Felderer, B., Fikel, M., Krieger, U., &amp; Blom, A. G. (2021). Recruiting a probability-based online panel via postal mail: Experimental evidence. <em>Social Science Computer Review</em>.
</div>
<div id="ref-Eckman2022" class="csl-entry" role="listitem">
Eckman, S., Unangst, J., Dever, J. A., &amp; Antoun, C. (2022). <span class="nocase">The Precision of Estimates of Nonresponse Bias in Means</span>. <em>Journal of Survey Statistics and Methodology</em>. <a href="https://doi.org/10.1093/jssam/smac019">https://doi.org/10.1093/jssam/smac019</a>
</div>
<div id="ref-felderer2019effect" class="csl-entry" role="listitem">
Felderer, B., Kirchner, A., &amp; Kreuter, F. (2019). The effect of survey mode on data quality: Disentangling nonresponse and measurement error bias. <em>Journal of Official Statistics</em>, <em>35</em>(1), 93–115.
</div>
<div id="ref-felderer2023using" class="csl-entry" role="listitem">
Felderer, B., Kueck, J., &amp; Spindler, M. (2023). Using double machine learning to understand nonresponse in the recruitment of a mixed-mode online panel. <em>Social Science Computer Review</em>, <em>41</em>(2), 461–481.
</div>
<div id="ref-friedel2023early" class="csl-entry" role="listitem">
Friedel, S., Felderer, B., Krieger, U., Cornesse, C., &amp; Blom, A. G. (2023). The early bird catches the worm! Setting a deadline for online panel recruitment incentives. <em>Social Science Computer Review</em>, <em>41</em>(2), 370–389.
</div>
<div id="ref-Gabler2015" class="csl-entry" role="listitem">
Gabler, S., Kolb, J.-P., Sand, M., &amp; Zins, S. (2015). Gewichtung. <em>Mannheim, GESIS – Leibniz-Institut Für Sozialwissenschaften (GESIS Survey Guidelines)</em>. <a href="https://doi.org/10.15465/gesis-sg_007">https://doi.org/10.15465/gesis-sg_007</a>
</div>
<div id="ref-green1991reluctant" class="csl-entry" role="listitem">
Green, K. E. (1991). Reluctant respondents: Differences between early, late, and nonresponders to a mail survey. <em>The Journal of Experimental Education</em>, <em>59</em>(3), 268–276.
</div>
<div id="ref-groves2006nonresponse" class="csl-entry" role="listitem">
Groves, R. M. (2006). Nonresponse rates and nonresponse bias in household surveys. <em>Public Opinion Quarterly</em>, <em>70</em>(5), 646–675.
</div>
<div id="ref-groves2008issues" class="csl-entry" role="listitem">
Groves, R. M., Brick, J. M., Couper, M., Kalsbeek, W., Harris-Kojetin, B., Kreuter, F., Pennell, B.-E., Raghunathan, T., Schouten, B., Smith, T., Tourangeau, R., Bowers, A., Jans, M., Kennedy, C., Levenstein, R., Olson, K., Peytcheva, E., Ziniel, S., &amp; Wagner, J. (2008). Issues facing the field: Alternative practical measures of representativeness of survey respondent pools. <em>Survey Practice</em>, <em>1</em>(3), 2910.
</div>
<div id="ref-groves2010total" class="csl-entry" role="listitem">
Groves, R. M., &amp; Lyberg, L. (2010). Total survey error: Past, present, and future. <em>Public Opinion Quarterly</em>, <em>74</em>(5), 849–879.
</div>
<div id="ref-groves2008impact" class="csl-entry" role="listitem">
Groves, R. M., &amp; Peytcheva, E. (2008). The impact of nonresponse rates on nonresponse bias: A meta-analysis. <em>Public Opinion Quarterly</em>, <em>72</em>(2), 167–189.
</div>
<div id="ref-Koch2015" class="csl-entry" role="listitem">
Koch, A., &amp; Blohm, M. (2015). Nonresponse bias. <em>Mannheim, GESIS – Leibniz-Institut Für Sozialwissenschaften (GESIS Survey Guidelines)</em>. <a href="https://doi.org/10.15465/gesis-sg_004">https://doi.org/10.15465/gesis-sg_004</a>
</div>
<div id="ref-krueger2014assessing" class="csl-entry" role="listitem">
Krueger, B. S., &amp; West, B. T. (2014). Assessing the potential of paradata and other auxiliary data for nonresponse adjustments. <em>Public Opinion Quarterly</em>, <em>78</em>(4), 795–831.
</div>
<div id="ref-little1986survey" class="csl-entry" role="listitem">
Little, R. J. (1986). Survey nonresponse adjustments for estimates of means. <em>International Statistical Review/Revue Internationale de Statistique</em>, 139–157.
</div>
<div id="ref-lugtig2022nonresponse" class="csl-entry" role="listitem">
Lugtig, P., Roth, K., Schouten, B., et al. (2022). Nonresponse analysis in a longitudinal smartphone-based travel study. <em>Survey Research Methods</em>, <em>16</em>(1), 13–27.
</div>
<div id="ref-nishimura2016alternative" class="csl-entry" role="listitem">
Nishimura, R., Wagner, J., &amp; Elliott, M. (2016). Alternative indicators for the risk of non-response bias: A simulation study. <em>International Statistical Review</em>, <em>84</em>(1), 43–62.
</div>
<div id="ref-peytcheva2009using" class="csl-entry" role="listitem">
Peytcheva, E., &amp; Groves, R. M. (2009). Using variation in response rates of demographic subgroups as evidence of nonresponse bias in survey estimates. <em>Journal of Official Statistics</em>, <em>25</em>(2), 193.
</div>
<div id="ref-roberts2020validation" class="csl-entry" role="listitem">
Roberts, C., Vandenplas, C., &amp; Herzing, J. (2020). Validation of r-indicators as a measure of the risk of bias using data from a non-response follow-up survey. <em>Journal of Official Statistics</em>, <em>36</em>(3), 675–701.
</div>
<div id="ref-sampcompr" class="csl-entry" role="listitem">
Rohr, B. (2023). <em>SampcompR: Comparing and visualizing differences between surveys. R package version 0.1.0.0</em>. <a href="https://github.com/BjoernRohr/sampcompR">https://github.com/BjoernRohr/sampcompR</a>
</div>
<div id="ref-Rohr2023" class="csl-entry" role="listitem">
Rohr, B., Silber, H., &amp; Felderer, B. (2023). Comparing the accuracy of univariate, bivariate, and multivariate estimates across probability and non-probability surveys with population benchmarks. <em>SocArXiv. March 4. Doi:10.31235/Osf.io/N6ehf</em>.
</div>
<div id="ref-rubin1987multiple" class="csl-entry" role="listitem">
Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys. hoboken</em>. John Wiley &amp; Sons.
</div>
<div id="ref-Sand2020" class="csl-entry" role="listitem">
Sand, M., &amp; Kunz, T. (2020). Gewichtung in der <span>P</span>raxis. <em>Mannheim, GESIS – Leibniz-Institut Für Sozialwissenschaften (GESIS Survey Guidelines)</em>. <a href="https://doi.org/10.15465/gesis-sg_030">https://doi.org/10.15465/gesis-sg_030</a>
</div>
<div id="ref-schouten2009indicators" class="csl-entry" role="listitem">
Schouten, B., Cobben, F., &amp; Bethlehem, J. (2009). Indicators for the representativeness of survey response. <em>Survey Methodology</em>, <em>35</em>(1), 101–113.
</div>
<div id="ref-schouten2010indicators" class="csl-entry" role="listitem">
Schouten, B., Shlomo, N., &amp; Skinner, C. (2010). <em>Indicators for monitoring and improving representativeness of response</em>.
</div>
<div id="ref-VanBuuren2011" class="csl-entry" role="listitem">
Van Buuren, S., &amp; Groothuis-Oudshoorn, K. (2011). <span class="nocase">mice: Multivariate imputation by Chained Equations in R</span>. <em>Journal of Statistical Software</em>, <em>45</em>(3), 1–67. <a href="https://doi.org/10.18637/jss.v045.i03">https://doi.org/10.18637/jss.v045.i03</a>
</div>
<div id="ref-wagner2010fraction" class="csl-entry" role="listitem">
Wagner, J. (2010). The fraction of missing information as a tool for monitoring the quality of survey data. <em>Public Opinion Quarterly</em>, <em>74</em>(2), 223–243.
</div>
<div id="ref-wagner2012comparison" class="csl-entry" role="listitem">
Wagner, J. (2012). A comparison of alternative indicators for the risk of nonresponse bias. <em>Public Opinion Quarterly</em>, <em>76</em>(3), 555–575.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{felderer2024,
  author = {Felderer, Barbara},
  publisher = {GESIS Leibniz-Institute for the Social Sciences},
  title = {Nonresponse {Bias} {Analysis}},
  date = {2024-01-01},
  address = {Mannheim},
  doi = {10.15465/gesis-sg_en_047},
  langid = {en},
  abstract = {Declining response rates increase the fear of nonresponse
    bias. This guideline discusses the relationship between nonresponse
    and nonrespones bias and gives an overview of indicators that are
    frequently used to determine the risk of nonresponse bias. The
    indicators are illustrated in a simulated data example.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-felderer2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Felderer, B. (2024). Nonresponse Bias Analysis. In <em>GESIS Survey
Guidelines</em>. GESIS Leibniz-Institute for the Social Sciences. <a href="https://doi.org/10.15465/gesis-sg_en_047">https://doi.org/10.15465/gesis-sg_en_047</a>
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Standort Mannheim</strong><br>
GESIS - Leibniz-Institut für Sozialwissenschaften<br>
B6, 4-5<br>
68159 Mannheim<br>
Telefon: +49-(0)621-1246-0<br>
Fax: +49-(0)621-1246-100</p>
</div>   
    <div class="nav-footer-center">
<p><strong>Standort Köln</strong><br>
GESIS - Leibniz-Institut für Sozialwissenschaften<br>
Unter Sachsenhausen 6-8<br>
50667 Köln<br>
Telefon: +49-(0)221-47694-0<br>
Fax: +49-(0)221-47694-199</p>
</div>
    <div class="nav-footer-right">
<p>Impressum Datenschutz</p>
</div>
  </div>
</footer>




</body></html>